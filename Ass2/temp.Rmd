---
title: "Assignment 2"
author: "Martynas Vaznonis, Andrei Puchkov, Carlo Peron"
date: "2024-03-08"
output: pdf_document
fontsize: 11pt
highlight: tango
editor_options: 
  markdown: 
    wrap: 72
---


```{r setup, include=FALSE}
options(digits=3)

library(ggplot2)
library(glmnet)

data <- read.table('fruitflies.txt', header = TRUE)
data$loglongevity <- log(data$longevity)
```

## Exercice 1


**a)** After loading in the data and adding a column for the log of longevity we create the plots seen below. From the plot it seems like there may be a difference among the different levels of activity but it is not perfectly clear. On the other hand, a correlation between the log of longevity and thorax length is already likely from the plot. To clarify if sexual activity had an effect on the longevity, we ran a 1-way ANOVA test. The test showed that there is indeed a significant difference in the longevity of a fruit fly based on its sexual activity.

```{r, fig.height=4, fig.width=10}
gridExtra::grid.arrange(
ggplot(data, aes(x = activity, y = loglongevity)) + geom_boxplot() +
  labs(title = 'Sexual Activity vs Longevity'),
ggplot(data, aes(x = thorax, y = loglongevity, color = activity)) + geom_point() +
  labs(title = 'Longevity vs Thorax'), ncol=2)
```

```{r}
activityaov = lm(loglongevity ~ activity, data=data)
anova(activityaov)
```

Finally, we check what the mean log of longevity is per level of sexual activity and found that the virgin flies live longer. In other words, it seems that the more poontang a fly gets, the faster it dies.

```{r}
tapply(data$loglongevity, data$activity, mean)
```


**b)** The positive coefficient for thorax suggests that flies with longer thorax lengths tend to have a higher estimated longevity. The predicted results show variance in longevity given the average thorax for different activity levels. The highest expected longevity is seen in the isolated case while the lowest in the high case. Thus, under this model too, the longevity decreases with sexual activity.

```{r}
loglongaov = lm(loglongevity ~ thorax + activity, data=data); summary(loglongaov)

average_thorax <- mean(data$thorax)
predictions <- data.frame(activity=unique(data$activity), thorax=average_thorax)
rbind(predictions$activity, round(predict(loglongaov, newdata=predictions), 3))
```


**c)** It is clear to see that the longevity is correlated with the thorax length from the plots below. Whether there is any difference in the influence of thorax among the levels of activity is not as clear. To test this, we run an ANOVA test with interaction between thorax length and sexual activity. If they interact, that means that the effect of thorax length is not the same across the groups of activity. Because we do not observe a significant contribution of the interaction term, we conclude that thorax length affects the longevity of all fruit flies the same.

```{r, echo=FALSE, results='hide', warning=FALSE, fig.height=4, fig.width=10}
gridExtra::grid.arrange(
  ggplot(data, aes(x = thorax, y = loglongevity, color = activity)) +
    geom_point() +
    facet_wrap(~activity) +
    labs(title = 'Longevity vs Thorax, faceted by Activity',
         x = 'Thorax Length',
         y = 'Log longevity') +
    theme_minimal(),
  ggplot(data, aes(x = thorax, y = loglongevity, color = activity)) +
    geom_point() +
    geom_smooth(formula = y ~ x, method = "lm", se = FALSE, linetype = "dashed", aes(group = 1)) +
    labs(title = 'Longevity vs Thorax',
         x = 'Thorax Length',
         y = 'Log longevity') +
    theme_minimal(), ncol=2)
```

```{r}
interaction_model <- lm(loglongevity ~ thorax * activity, data=data)
anova(interaction_model)
```


**d)** The analysis with thorax length is more complete. Because the thorax affects all levels of the activity factor identically, the results of both analyses coincide in terms of the significance of the activity factor but this may not always be the case. Therefore, including thorax leads to a more correct model. Furthermore, the test below shows that including thorax, significantly enhances the model.

```{r}
anova(activityaov, loglongaov)
```


**e)** The plots below show that the longevity is likely normally distributed while the log of longevity is likely not. Further evidence for this is provided by the Shapiro-Wilk tests. The residuals for both models seem pretty good and likely normal. Since, ANOVA requires normally distributed samples, it is better to use the number of days as the response rather than the logarithm of it.

```{r}
longaov = lm(longevity ~ thorax + activity, data=data)

par(mfrow=c(2, 2)); hist(data$longevity); qqnorm(data$longevity)
hist(data$loglongevity); qqnorm(data$loglongevity)
shapiro.test(data$longevity)[2]; shapiro.test(data$loglongevity)[2]

qqnorm(residuals(loglongaov)); plot(fitted(loglongaov), residuals(loglongaov))
qqnorm(residuals(longaov)); plot(fitted(longaov), residuals(longaov))
```


## Exercice 2


```{r, include=FALSE}
library(car)

data <- read.csv("BirthWeight.csv")
potential <- data[,!names(data) %in% c('ID', 'lowbwt', 'mage35', 'smoker')]
```


**a)** Spotting potential points is difficult visually in multidimensional space, but we only need to check for influence points as those are the only significant outliers. To analyze the problem of influence points, we're going to use Cook's distance. This method quantifies influence points in the dataset by measuring how much change that point contributes to in the final model. No influence points are present within the current model. This is unsurprising however, because of the high dimensionality of the data.

```{r}
# potential is a table with only the potential predictors
model_all = lm(Birthweight ~ ., data=potential)
cook <- as.data.frame(cooks.distance(model_all))
length(cook[cook>=1])
```

To check collinearity we can use a correlation matrix and pairwise correlation plots. But given the large number of potential predictors, these measures would likely be overwhelming to look at and so, bad for analysis. Instead we use VIF for a more concise description of collinearity. We can see relatively little collinearity with no predictor VIF$_j$ > 5. The highest VIF value is for *fage*, which likely correlates with *mage* and potentially *fedyrs*.

```{r}
vif(model_all)
```


**b)** At the end of the loop, we can see every dropped predictor. The first was *fage* and the last *mppwt* with a total of 9 predictors dropped and 2 ones remaining. The variables left are *headcirc* and *gestation* which seem like very natural choices for estimating the birth weight of a child.

```{r}
reduced_model <- model_all
drop = NULL
repeat{
  p_values = summary(reduced_model)$coefficients[,c(0, 4)]
  max_p = max(p_values)
  if(max_p <= 0.05) break
  var = which.max(p_values)
  drop = c(drop, names(var))
  reduced_model <- update(reduced_model, as.formula(paste(". ~ . -", names(var))))
}
summary(reduced_model)
drop
```

Checking for the model assumptions below we can see that there are no issues with collinearity nor outliers. The residuals seem a little off in the qq plot but a Shapiro-Wilk test (not shown here) does not reject normality.

```{r, fig.height=3, fig.width=6}
vif(reduced_model); paste("# of outliers: ", sum(cooks.distance(reduced_model)>1))
par(mfrow=c(1, 2)); qqnorm(residuals(reduced_model))
plot(fitted(reduced_model), residuals(reduced_model))
```


**c)** Below we can see the mean predicted birth weight value for the average baby with a 95% confidence and prediction interval respectively.

```{r}
average_values <- data.frame(Headcirc = mean(data$Headcirc),
                             Gestation = mean(data$Gestation))
predict(reduced_model, newdata = average_values, interval = "confidence")[,]
predict(reduced_model, newdata = average_values, interval = "prediction")[,]
```

**d)** The LASSO method is a numerical optimization method rather than an analytical solution. Therefore, the MSE on the validation set is better modeled as a random variable. Moreover, the train-validation split is randomized as well, further contributing to the uncertainty not only of the LASSO model but also of the step down model. Thus, to compare the models derived with the LASSO method below with the model in **b)**, we need to train them a myriad of times. Similarly, we need to fit a different model each time for the predictors derived with the step down strategy to account for different train-validation splits. Then running ANOVA, we see that there is a significant difference among the conditions. Further investigations show that the worst model is indeed the one derived from the step down method. The best is the one that uses the 1sd $\lambda$ value. The overall difference in the MSE however is still quite small.

The LASSO method, like the step down one, selected **Headcirc** and **Gestation** as significant predictors for the baby's body weight. But alongside those, it also selected **Length**.

```{r}
mse <- function(pred, y){ # Shortcut to get the MSE
  return(mean(pred - y)^2)
}

x = as.matrix(potential[,names(potential) != "Birthweight"])
y = potential$Birthweight

df <- data.frame(matrix(ncol=3, nrow=0, dimnames=list(
  NULL, c("lambda.min", "lambda.1se", "step.down"))))

for(i in 1:1000){
  # New train-validation split
  train = sample(1:nrow(x), 0.67*nrow(x))
  x.train = x[train,]; y.train = y[train]
  x.val = x[-train,]; y.val = y[-train]
  
  # Fit a new LASSO and reduced model
  lasso.model = glmnet(x.train, y.train, alpha=1)
  lasso.cv = cv.glmnet(x.train, y.train, alpha=1, type.measure="mse", nfolds=5)
  red.mod = lm(reduced_model$call[[2]], data=potential[train,])
  
  # Append the MSEs to the dataframe
  df[nrow(df) + 1,] = c(
  mse(predict(lasso.model, s=lasso.cv$lambda.min, newx=x.val), y.val),
  mse(predict(lasso.model, s=lasso.cv$lambda.1se, newx=x.val), y.val),
  mse(predict(red.mod, newdata=potential[-train,]), potential[-train,]$Birthweight))
}

anova(lm(values ~ ind, data=stack(df)))
```


**e)** Below we can see how many babies were born underweight. First we discriminate by smoker and then by the mother's age. Both smoking and age seem to have a positive correlation with being born underweight. Notably, there are only four mothers over the age of 35 in the dataset which could misrepresent the actual proportion of the malnourished babies in this demographic. The bar plot indicates that smoking has a greater effect than age on low birth weight.

Performing independent t-tests (not shown here) between smokers and non smokers as well as between mothers over and under 35 revealed no statistical differences.

```{r, include=FALSE}
uwt <- data
uwt$smoker = factor(uwt$smoker, levels=c(0, 1), labels=c("Non smoker", "Smoker"))
uwt$mage35 = factor(uwt$mage35, levels=c(0, 1), labels=c("Not over 35", "Over 35"))
```

```{r, fig.height=4, fig.width=6}
# Number of underweight babies
tapply(uwt$lowbwt, uwt$smoker, function(x) paste(sum(x), "out of", length(x)))
tapply(uwt$lowbwt, uwt$mage35, function(x) paste(sum(x), "out of", length(x)))

# Summary table
xtabs(lowbwt ~ smoker + mage35, data=uwt)

barplot(xtabs(lowbwt ~ smoker + mage35, data=uwt), main="Low birth weight",
        ylab="Number of underweight babies", legend=unique(uwt$smoker))
```


**f)** The logistic regression model appears in line with what we have seen in **e)**, which is to say that smoking and old age do not significantly contribute to low birth weight. On the other hand, the explanatory variable gestation did have a significant effect. The way it can be interpreted is that one unit increase in gestation multiplies the odds of being born underweight by $e^{-1.463}$. In other words, gestation corresponds to a reduced likelihood of a low weight birth.

```{r}
logistic.model = glm(lowbwt ~ Gestation+smoker+mage35, data=data, family="binomial")
summary(logistic.model)
```


**g)** In both cases, the interactions are insignificant, and in the case of the model with smoker:Gestation interaction, all predictors lost their significance. Thus, it is best to stick to the model in **f)** which was the simplest while still explaining the most data. 

```{r, warning=FALSE}
logistic.smoker = glm(lowbwt ~ Gestation*smoker+mage35, data=data, family="binomial")
logistic.mage35 = glm(lowbwt ~ Gestation*mage35+smoker, data=data, family="binomial")
```


**h)** As expected, the lowest probability of a low weight birth is when the mother is young and does not smoke. Smoking has a bigger influence than age on pushing the probability towards such a birth and the synergy of both leads to the highest odds of *lowbwt*. Regardless, both smoking and age are overshadowed by gestation leading to overall very slim chances of abnormally low birth weights across the board.

```{r}
new = data.frame(Gestation=40, mage35=unique(data$mage35),
                 smoker=rep(unique(data$smoker), each=2))
new$pred = predict(logistic.model, newdata=new, type="response")
new
```


**i)** We create contingency tables for *smoker*/*lowbwt* and *mage35*/*lowbwt* to examine the question outlined in **e)**. Then, we attempted to use the `chisq.test` to determine if these factors were related but because in both cases half of $E_{ij}<5$, the $\chi^2$ approximation is unreliable. Luckily, these are $2x2$ tables so we can use Fisher's exact test instead. Just as before, we find no significant relation between smoking/age and low birth weight.

```{r, warning=FALSE}
fisher.test(table(data[,c("smoker", "lowbwt")]))
fisher.test(table(data[,c("lowbwt", "mage35")]))
```


## Exercice 3


**a)**

```{r}
```


**b)**

```{r}
```


**c)**

```{r}
```